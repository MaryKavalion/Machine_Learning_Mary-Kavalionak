{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = \"filepath\",\n",
    "        save_best_only = True,\n",
    "        monitor = 'val_loss'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = keras.model.load_model('name')\n",
    "test_loss, test_acc = test_model.evaluate (test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip('horizontal'),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for images, _ in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i+1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype('unit8'))\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape = (180, 180, 3))\n",
    "x = data_augmentation(input)\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = Conv2D(filters = 32, kernel_size=3, activation = 'relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size = 2)(x)\n",
    "x = layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size = 2)(x)\n",
    "x = layers.Conv2D(filters = 128, kernel_size = 3, activation = 'relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size = 2)(x)\n",
    "x = layers.Conv2D(filters = 256, kernel_size = 3, activation = 'relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size = 2)(x)\n",
    "x = layers.Conv2D(filters = 256, kernel_size = 3, activation = 'relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "model = keras.Model (inputs = inputs, outputs = outputs)\n",
    "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = 'filepath',\n",
    "        save_best_only = True,\n",
    "        monitor = 'val_loss'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = keras.applications.vgg16.VGG16(\n",
    "    weights = 'imagenet',\n",
    "    include_top = False,\n",
    "    input_shape = (180,180,3)\n",
    ") # ready network\n",
    "# VGG16 — это популярная архитектура сверточной нейронной сети, разработанная для классификации изображений. \n",
    "# Она была обучена на большом наборе данных ImageNet, содержащем миллионы изображений, и может классифицировать их на 1000 классов.\n",
    "# Эта модель используется в задачах трансферного обучения (transfer learning), \n",
    "# что позволяет перенести знания, полученные при обучении на одном наборе данных, на решение другой задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_features_and_labels(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for images, labels in dataset:\n",
    "        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
    "        features = conv_base.predict(preprocessed_images)\n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels)\n",
    "    return np.concatenate(all_features), np.concatenate(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = get_features_and_labels (train_dataset)\n",
    "# same for test and validation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape = (5,5,512))\n",
    "x = layers.Flatten()(inputs)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'rmsprop',\n",
    "              metrics = ['accuracy'])\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='feature_extraction.keras',\n",
    "        save_best_only = True,\n",
    "        monitor = 'val_loss'\n",
    "    )\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
